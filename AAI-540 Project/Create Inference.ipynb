{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4de76edc-e963-4a6d-880e-43df2fe83159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load model when the container starts\n",
    "MODEL_PATH = \"/opt/ml/model/model.xgb\"\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Load the trained model\"\"\"\n",
    "    model = xgb.Booster()\n",
    "    model.load_model(os.path.join(model_dir, \"model.xgb\"))\n",
    "    return model\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \"\"\"Parse input data from JSON\"\"\"\n",
    "    if request_content_type == \"application/json\":\n",
    "        data = json.loads(request_body)[\"instances\"]\n",
    "        return np.array(data)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported content type: {request_content_type}\")\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"Make predictions\"\"\"\n",
    "    dmatrix = xgb.DMatrix(input_data)\n",
    "    predictions = model.predict(dmatrix)\n",
    "    return predictions.tolist()\n",
    "\n",
    "def output_fn(predictions, response_content_type):\n",
    "    \"\"\"Format output\"\"\"\n",
    "    return json.dumps({\"predictions\": predictions})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc7e0ef2-f012-429e-92fc-2259f5c80b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ inference.py file created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the inference script\n",
    "script_content = \"\"\"import os\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load model when the container starts\n",
    "MODEL_PATH = \"/opt/ml/model/model.xgb\"\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \\\"\\\"\\\"Load the trained model\\\"\\\"\\\"\n",
    "    model = xgb.Booster()\n",
    "    model.load_model(os.path.join(model_dir, \"model.xgb\"))\n",
    "    return model\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    \\\"\\\"\\\"Parse input data from JSON\\\"\\\"\\\"\n",
    "    if request_content_type == \"application/json\":\n",
    "        data = json.loads(request_body)[\"instances\"]\n",
    "        return np.array(data)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported content type: {request_content_type}\")\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \\\"\\\"\\\"Make predictions\\\"\\\"\\\"\n",
    "    dmatrix = xgb.DMatrix(input_data)\n",
    "    predictions = model.predict(dmatrix)\n",
    "    return predictions.tolist()\n",
    "\n",
    "def output_fn(predictions, response_content_type):\n",
    "    \\\"\\\"\\\"Format output\\\"\\\"\\\"\n",
    "    return json.dumps({\"predictions\": predictions})\n",
    "\"\"\"\n",
    "\n",
    "# Write to a file\n",
    "with open(\"inference.py\", \"w\") as f:\n",
    "    f.write(script_content)\n",
    "\n",
    "print(\"✅ inference.py file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fc2ec8a-ba3f-444e-a156-edb47d107ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does inference.py exist? ➝ True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Does inference.py exist? ➝\", os.path.exists(\"inference.py\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a227c9bf-0dc0-4bcf-a236-0d0f5298d6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference script uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3_client = boto3.client(\"s3\")\n",
    "bucket_name = \"network-anomaly-dataset-001aefd6\"\n",
    "script_path = \"inference.py\"\n",
    "s3_key = \"sagemaker/inference.py\"  # Define where in S3 to store it\n",
    "\n",
    "s3_client.upload_file(script_path, bucket_name, s3_key)\n",
    "\n",
    "print(\"Inference script uploaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f1d246-9569-4d06-8ffd-92a9144fa117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
